{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def main():\n",
        "    # Load the dataset from the Excel file\n",
        "    df = pd.read_excel('/content/Book1.xlsx')\n",
        "\n",
        "    # Strip leading/trailing spaces from column names\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # Extract texts from ENGLISH and HINDI columns\n",
        "    english_texts = df['ENGLISH'].tolist()\n",
        "    hindi_texts = df['HINDI'].tolist()\n",
        "\n",
        "    # Create labels for the texts (0 for English, 1 for Hindi)\n",
        "    english_labels = [0] * len(english_texts)\n",
        "    hindi_labels = [1] * len(hindi_texts)\n",
        "\n",
        "    # Combine the texts and labels\n",
        "    texts = english_texts + hindi_texts\n",
        "    labels = english_labels + hindi_labels\n",
        "\n",
        "    # Create a TF-IDF Vectorizer and fit_transform the text data\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train a K-Nearest Neighbors classifier with k=3\n",
        "    k = 3\n",
        "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
        "    neigh.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on both training and test sets\n",
        "    y_train_pred = neigh.predict(X_train)\n",
        "    y_test_pred = neigh.predict(X_test)\n",
        "\n",
        "    # Generate confusion matrices\n",
        "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
        "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    # Print confusion matrices\n",
        "    print(\"Confusion Matrix for Training Set:\")\n",
        "    print(cm_train)\n",
        "    print(\"Confusion Matrix for Test Set:\")\n",
        "    print(cm_test)\n",
        "\n",
        "    # Print classification reports\n",
        "    print(\"\\nClassification Report for Training Set:\")\n",
        "    print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "    print(\"\\nClassification Report for Test Set:\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    # Evaluate the model\n",
        "    train_accuracy = neigh.score(X_train, y_train)\n",
        "    test_accuracy = neigh.score(X_test, y_test)\n",
        "\n",
        "    print(\"\\nTraining Accuracy:\", train_accuracy)\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "    if train_accuracy > test_accuracy:\n",
        "        print(\"\\nThe model is likely overfitting.\")\n",
        "    elif train_accuracy < test_accuracy:\n",
        "        print(\"\\nThe model is likely underfitting.\")\n",
        "    else:\n",
        "        print(\"\\nThe model is likely well-fitted.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8ozFTLVs-uA",
        "outputId": "9c30ae0b-f0a5-4d5a-e3b9-75ef5b49a742"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Training Set:\n",
            "[[ 797 1337]\n",
            " [   0 2151]]\n",
            "Confusion Matrix for Test Set:\n",
            "[[163 764]\n",
            " [  0 910]]\n",
            "\n",
            "Classification Report for Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.37      0.54      2134\n",
            "           1       0.62      1.00      0.76      2151\n",
            "\n",
            "    accuracy                           0.69      4285\n",
            "   macro avg       0.81      0.69      0.65      4285\n",
            "weighted avg       0.81      0.69      0.65      4285\n",
            "\n",
            "\n",
            "Classification Report for Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.18      0.30       927\n",
            "           1       0.54      1.00      0.70       910\n",
            "\n",
            "    accuracy                           0.58      1837\n",
            "   macro avg       0.77      0.59      0.50      1837\n",
            "weighted avg       0.77      0.58      0.50      1837\n",
            "\n",
            "\n",
            "Training Accuracy: 0.6879813302217036\n",
            "Test Accuracy: 0.5841045182362548\n",
            "\n",
            "The model is likely overfitting.\n"
          ]
        }
      ]
    }
  ]
}